Traceback (most recent call last):
  File "/home/Matheart/miniconda3/envs/statml/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/Matheart/miniconda3/envs/statml/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/Matheart/Code/DomainBed/domainbed/scripts/train.py", line 216, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
  File "/home/Matheart/Code/DomainBed/domainbed/algorithms.py", line 2017, in update
    loss = F.cross_entropy(output, y)
  File "/home/Matheart/miniconda3/envs/statml/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/home/Matheart/miniconda3/envs/statml/lib/python3.9/site-packages/torch/optim/adam.py", line 108, in step
    F.adam(params_with_grad,
  File "/home/Matheart/miniconda3/envs/statml/lib/python3.9/site-packages/torch/optim/functional.py", line 87, in adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
KeyboardInterrupt
